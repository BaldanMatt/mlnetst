{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import anndata\n",
    "import anndata as ad\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pypath.inputs.biomart\n",
    "import torch\n",
    "from bokeh.transform import transform\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import norm\n",
    "from typing import Tuple"
   ],
   "id": "1f5902a20cc2ea71",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading data",
   "id": "58ee2d7c4f76d36c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "x_hat_s = anndata.read_h5ad(Path(os.getcwd()).parents[0] / \"data\" / \"processed\" / \"mouse1_slice153_x_hat_s.h5ad\")",
   "id": "8cddd367bb48c5ec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Method\n",
    "## Calculate Ligand and Receptor score\n",
    "\n",
    "For each ligand (receptor) _g_ in cluster _k_, we compute a score $S(g,k)\\in [0,1]$ aimed at measuring how much the observed ligand (receptor) average expression level $\\bar{X}_{g}^{k}$ is high compared to the average expression levels observable by ranche for random genes in the same cluster _k_. The distribution of average gene expression level observable by chance was obtained, using a permutation approach, as follows:\n",
    "i) randomly permuting row/genes in matrix $X^k$ independently for each column/cell;\n",
    "ii) computing the average genes expression levels in such shuffled version of $X^{k}$;\n",
    "iii) iterating steps (i) and (ii) multiple times."
   ],
   "id": "d1d490a33927ca84"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import liana as li\n",
    "lr_df = li.resource.select_resource(\"mouseconsensus\")\n",
    "lr_df[\"ligand\"]=lr_df[\"ligand\"].str.lower()\n",
    "lr_df[\"receptor\"]=lr_df[\"receptor\"].str.lower()"
   ],
   "id": "5007835cf60bc34",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculate Ligand and Receptor Pair Score",
   "id": "c6c3d6d77e74b9a2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Define utility functions to evaluate the intercellular scores",
   "id": "ec4ce148de4d4f2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_gene_cluster_stats(adata: ad.AnnData, cluster_key=\"@label\", verbose: int = 0) -> ad.AnnData:\n",
    "    clusters = adata.obs[cluster_key].cat.categories\n",
    "    cluster_stats = {}\n",
    "    for cluster in clusters:\n",
    "        if verbose == 1 | verbose == 2:\n",
    "            print(f\"\\nProcessing cluster: {cluster}\")\n",
    "        cell_mask = adata.obs[cluster_key] == cluster\n",
    "        cluster_data = adata[cell_mask].X\n",
    "        cluster_stats[cluster] = {\n",
    "            \"mu\": np.mean(cluster_data, axis=None),\n",
    "            \"sd\": np.std(cluster_data, axis=None),\n",
    "            \"counts\": cluster_data.shape[0]\n",
    "        }\n",
    "        gene_means = np.mean(cluster_data, axis=0)\n",
    "        gene_scores = norm.cdf(gene_means, loc=cluster_stats[cluster][\"mu\"],\n",
    "                               scale=cluster_stats[cluster][\"sd\"] / np.sqrt(cluster_stats[cluster][\"counts\"]))\n",
    "        gene_scores[gene_means == 0] = 0\n",
    "        score_key = f'score_{cluster}'\n",
    "        adata.var[score_key] = gene_scores\n",
    "\n",
    "    return adata"
   ],
   "id": "f3b5ec60e5f4e5ad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def prepare_lr_data(adata: ad.AnnData, lr_pairs_df: pd.DataFrame, verbose: int = 0) -> Tuple[ad.AnnData, pd.DataFrame]:\n",
    "    # First, identify complex molecules\n",
    "    lr_pairs_df[\"is_ligand_complex\"] = lr_pairs_df[\"ligand\"].str.contains(\"_\")\n",
    "    lr_pairs_df[\"ligand_complex_components\"] = lr_pairs_df[\"ligand\"].str.split(\"_\")\n",
    "    lr_pairs_df[\"is_receptor_complex\"] = lr_pairs_df[\"receptor\"].str.contains(\"_\")\n",
    "    lr_pairs_df[\"receptor_complex_components\"] = lr_pairs_df[\"receptor\"].str.split(\"_\")\n",
    "    lr_pairs_df[\"is_interaction_complex\"] = lr_pairs_df[\"is_ligand_complex\"] | lr_pairs_df[\"is_receptor_complex\"]\n",
    "\n",
    "    # Get all unique components\n",
    "    ligands = set(lr_pairs_df[\"ligand_complex_components\"].explode())\n",
    "    receptors = set(lr_pairs_df[\"receptor_complex_components\"].explode())\n",
    "\n",
    "    # Find which components exist in adata\n",
    "    valid_ligands = ligands.intersection(adata.var_names)\n",
    "    valid_receptors = receptors.intersection(adata.var_names)\n",
    "\n",
    "    # Filter lr_pairs_df to keep only pairs where all components exist in adata\n",
    "    valid_pairs_mask = lr_pairs_df.apply(\n",
    "        lambda row: all(comp in valid_ligands for comp in row[\"ligand_complex_components\"]) and\n",
    "                   all(comp in valid_receptors for comp in row[\"receptor_complex_components\"]),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    lr_pairs_df = lr_pairs_df[valid_pairs_mask].copy()\n",
    "\n",
    "    # Update adata to keep only genes that are part of valid pairs\n",
    "    all_valid_genes = valid_ligands.union(valid_receptors)\n",
    "    adata = adata[:, adata.var_names.isin(all_valid_genes)].copy()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Filtered from {len(ligands.union(receptors))} to {len(all_valid_genes)} total genes\")\n",
    "        print(f\"Filtered from {len(valid_pairs_mask)} to {valid_pairs_mask.sum()} valid L-R pairs\")\n",
    "\n",
    "    return adata, lr_pairs_df"
   ],
   "id": "92f402f9b4455870",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_lr_scores(adata: ad.AnnData, lr_pairs_df: pd.DataFrame, cluster_key=\"@label\", verbose: int = 0) -> pd.DataFrame:\n",
    "    # Create base L-R pairs first (more efficient)\n",
    "    lr_pairs = lr_pairs_df[\"ligand\"] + \"&\" + lr_pairs_df[\"receptor\"]\n",
    "    clusters = adata.obs[cluster_key].astype(\"category\").cat.categories\n",
    "\n",
    "    # Create all combinations\n",
    "    interactions = [\n",
    "        f\"{lr}&{source}&{target}\"\n",
    "        for lr in lr_pairs\n",
    "        for source in clusters\n",
    "        for target in clusters\n",
    "    ]\n",
    "\n",
    "    # Create DataFrame with ordered interactions\n",
    "    lr_scores = pd.DataFrame(\n",
    "        [x.split('&') for x in interactions],\n",
    "        columns=['ligand', 'receptor', 'source', 'target'],\n",
    "        index=interactions\n",
    "    )\n",
    "    lr_scores['is_ligand_complex'] = lr_scores['ligand'].str.contains(\"_\")\n",
    "    lr_scores['is_receptor_complex'] = lr_scores['receptor'].str.contains(\"_\")\n",
    "    lr_scores[\"ligand_score\"] = np.zeros(len(lr_scores))\n",
    "    lr_scores[\"receptor_score\"] = np.zeros(len(lr_scores))\n",
    "\n",
    "    def compute_complex_score(adata, complex_molecule: str, cluster_score_key: str) -> float:\n",
    "        components = complex_molecule.split(\"_\")\n",
    "        component_scores = adata.var.loc[components, cluster_score_key].values\n",
    "        complex_score = np.exp(np.mean(np.log(component_scores)))\n",
    "        return complex_score\n",
    "\n",
    "    for i, row in tqdm(enumerate(lr_scores.itertuples()), total=len(lr_scores), disable=verbose != 2, desc=\"Calculating L-R scores\"):\n",
    "        # print(f\"Processing interaction {row}\")\n",
    "        if row.is_ligand_complex:\n",
    "            lr_scores.loc[row[0],\"ligand_score\"] = compute_complex_score(adata, row.ligand, f\"score_{row.source}\")\n",
    "        else:\n",
    "            lr_scores.loc[row[0],\"ligand_score\"] = adata.var.loc[row.ligand,f\"score_{row.source}\"]\n",
    "        if row.is_receptor_complex:\n",
    "            lr_scores.loc[row[0],\"receptor_score\"] = compute_complex_score(adata, row.receptor, f\"score_{row.target}\")\n",
    "        else:\n",
    "            lr_scores.loc[row[0],\"receptor_score\"] = adata.var.loc[row.receptor, f\"score_{row.target}\"]\n",
    "        # print(f\"Processed interaction to {lr_scores.loc[row[0]]}\")\n",
    "    lr_scores[\"score\"] = np.minimum(lr_scores[\"ligand_score\"], lr_scores[\"receptor_score\"])\n",
    "\n",
    "    return lr_scores"
   ],
   "id": "3bf7395ce3cbc588",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data = x_hat_s.copy()\n",
    "data, complex_info = prepare_lr_data(data, lr_df)\n",
    "data = compute_gene_cluster_stats(data, cluster_key='subclass', verbose=2)"
   ],
   "id": "61b760e09ea7f9d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Calculate Intercellular scores",
   "id": "ab61db626b1bc451"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "try:\n",
    "    lr_scores = pd.read_csv(Path(os.getcwd()).parents[0] / \"data\" / \"processed\" / \"mouse1_slice153_lr_inter_scores.csv\",\n",
    "                            index_col=0)\n",
    "except FileNotFoundError:\n",
    "    lr_scores = compute_lr_scores(adata, complex_info, cluster_key='subclass', verbose=2)\n",
    "    lr_scores.to_csv(\n",
    "    Path(os.getcwd()).parents[0] / \"data\" / \"processed\" / \"mouse1_slice153_lr_inter_scores.csv\")"
   ],
   "id": "3a0644e8715fb7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# select top 3 lr pairs between clusters ASTRO and L2/3 IT\n",
    "source = \"Astro\"\n",
    "target = \"L2/3 IT\"\n",
    "df = lr_scores.query(f\"source == '{source}' & target == '{target}'\")\n",
    "df.sort_values(by=\"score\", ascending=False).head(10)"
   ],
   "id": "a889f13d4990ba01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import squidpy as sq\n",
    "fig, axs = plt.subplots(ncols = 2)\n",
    "axs = axs.flatten()\n",
    "data.obsm[\"spatial\"] = np.array([(x,y) for x,y in zip(data.obs[\"centroid_x\"], data.obs[\"centroid_y\"])])\n",
    "features = [\"gnai2\",\"cnr1\"]\n",
    "groups = [source, target]\n",
    "for i,ax in enumerate(axs):\n",
    "    sq.pl.spatial_scatter(\n",
    "        data[(data.obs[\"subclass\"] == groups[i]),:],\n",
    "        color = features[i],\n",
    "        shape=None,\n",
    "        size=10,\n",
    "        ax=ax,\n",
    "    )"
   ],
   "id": "a32e9a4890022373",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import seaborn as sns\n",
    "subset_lr_scores = lr_scores.query(f\"source == '{source}' & target == '{target}'\")\n",
    "sns.relplot(subset_lr_scores, kind=\"scatter\", x=\"ligand_score\", y=\"receptor_score\", row=\"source\", col=\"target\", hue=\"score\", palette=\"viridis\", aspect=1.5,\n",
    "            facet_kws=dict(margin_titles=True),)"
   ],
   "id": "91bbe8ad33a26fad",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's implement somewhat an idea of score with a distance metric\n",
   "id": "c099d9373c21d29f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch"
   ],
   "id": "fa746868832f53b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "subdata = data[(data.obs[\"subclass\"] == source) | (data.obs[\"subclass\"] == target),:]\n",
    "top_k_interactions = 200\n",
    "print(lr_df.shape)\n",
    "potential_interactions = lr_scores.query(f\"source == '{source}' & target == '{target}'\").loc[:,[\"ligand\",\"receptor\",\"score\"]].sort_values(by=\"score\",ascending=False).head(top_k_interactions)\n",
    "print(potential_interactions)"
   ],
   "id": "8f47e9551adabc3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_spatial_locations = subdata.shape[0]\n",
    "n_potential_interactions = potential_interactions.shape[0]\n",
    "x_lr = torch.zeros((n_spatial_locations, n_spatial_locations, n_potential_interactions), dtype=torch.float32)"
   ],
   "id": "d8f2d1b66bdbfdf0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Indexing torch tensors\n",
    "t = torch.ones((3,4,5), dtype=torch.float)\n",
    "print(f\"Shape: {t.size()}\")\n",
    "print(f\"First row 2D Matrix: {t[0,:,:]}\")\n",
    "## assigning zeros to whole first column on second dimension slice\n",
    "t[:,0,:] = 0\n",
    "# Joining tensors\n",
    "t1 = torch.cat([t,t], dim=1)\n",
    "# Arithmetic operations\n",
    "y1 = t[:,:,0] @ t[:,:,0].T\n",
    "y2 = t[:,:,0].matmul(t[:,:,0].T)\n",
    "y3 = torch.rand_like(y1)\n",
    "torch.matmul(t[:,:,0], t[:,:,0].T, out=y3)"
   ],
   "id": "92cd1992e43f0a12",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "potential_interactions",
   "id": "52fd71afc1b3d9f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "single_lr = torch.zeros((n_spatial_locations, n_spatial_locations), dtype=torch.float32)\n",
    "which_interaction_index = 0\n",
    "ligand_mask = torch.from_numpy(subdata[:, potential_interactions.iloc[which_interaction_index][\"ligand\"]].X)\n",
    "receptor_mask = torch.from_numpy(subdata[:, potential_interactions.iloc[which_interaction_index][\"receptor\"]].X)\n",
    "spatial_position_matrix = torch.tensor(subdata.obsm[\"spatial\"], dtype=torch.float32)\n",
    "print(spatial_position_matrix.shape)\n",
    "dist_matrix = torch.cdist(spatial_position_matrix, spatial_position_matrix, p=2)\n",
    "print(dist_matrix.shape)\n",
    "# How can i display these distances in a 2d plot\n"
   ],
   "id": "e2eba8fac0b70690",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "single_lr = torch.div(ligand_mask @ receptor_mask.T, dist_matrix + 1e-5)\n",
    "# set the diagonal to zero\n",
    "single_lr = single_lr.fill_diagonal_(0)\n"
   ],
   "id": "6eb9dcbfd45edd4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.boxplot(single_lr.numpy().flatten())\n",
    "plt.show()\n",
    "print(np.quantile(single_lr.numpy().flatten(), 0.95))"
   ],
   "id": "6fbb5f48e1148f63",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "bd7093e88d4d2a67"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import networkx as nx\n",
    "mask = single_lr > np.quantile(single_lr.numpy().flatten(), 0.95)\n",
    "masked_single_lr = single_lr * mask\n",
    "g = nx.from_numpy_array(masked_single_lr.numpy())\n",
    "pos = [(x,y) for x,y in zip(spatial_position_matrix[:,0].numpy(), spatial_position_matrix[:,1].numpy())]\n",
    "nx.draw(g, pos, node_size=10, node_color=\"blue\", alpha=0.5)"
   ],
   "id": "5dacb56437b3198d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Try to scale up",
   "id": "723ea278f051e328"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "try_top_interactions = 10\n",
    "spatial_position_matrix = torch.tensor(data.obsm[\"spatial\"], dtype=torch.float32)\n",
    "dist_matrix = torch.cdist(spatial_position_matrix, spatial_position_matrix, p=2)\n",
    "\n",
    "# first iteration\n",
    "ligand_mask = torch.from_numpy(data[:, potential_interactions.iloc[0][\"ligand\"]].X.astype(np.float32))\n",
    "receptor_mask = torch.from_numpy(data[:, potential_interactions.iloc[0][\"receptor\"]].X.astype(np.float32))\n",
    "single_lr = torch.div(ligand_mask @ receptor_mask.T, dist_matrix + 1e-5)\n",
    "single_lr = single_lr.fill_diagonal_(0)\n",
    "mask = single_lr > np.quantile(single_lr.numpy().flatten(), 0.95)\n",
    "masked_single_lr = single_lr * mask\n",
    "cells_inter_scores = masked_single_lr.to_sparse()\n",
    "for i,k in tqdm(enumerate(potential_interactions.index)):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    if i >= try_top_interactions:\n",
    "        break\n",
    "    ligand_mask = torch.from_numpy(data[:, potential_interactions.iloc[i][\"ligand\"]].X.astype(np.float32))\n",
    "    receptor_mask = torch.from_numpy(data[:, potential_interactions.iloc[i][\"receptor\"]].X.astype(np.float32))\n",
    "    single_lr = torch.div(ligand_mask @ receptor_mask.T, dist_matrix + 1e-5)\n",
    "    single_lr = single_lr.fill_diagonal_(0)\n",
    "    mask = single_lr > np.quantile(single_lr.numpy().flatten(), 0.95)\n",
    "    masked_single_lr = single_lr * mask\n",
    "    cells_inter_scores = torch.dstack([cells_inter_scores, masked_single_lr.to_sparse()])\n",
    "print(type(cells_inter_scores), cells_inter_scores.shape)\n",
    "print(cells_inter_scores)\n"
   ],
   "id": "ae181371f54bab87",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "which_interaction_index = 0\n",
    "# learn how to slice a sparse tensor, which is not supported, but we could index it (?)\n",
    "plt.figure(figsize=(40, 40))\n",
    "\n",
    "# Create the graph from the adjacency matrix\n",
    "adj = cells_inter_scores.to_dense()[:,:,which_interaction_index].numpy()\n",
    "g = nx.from_numpy_array(adj)\n",
    "\n",
    "# Get positions from spatial matrix\n",
    "pos = [(x,y) for x,y in zip(spatial_position_matrix[:,0].numpy(), spatial_position_matrix[:,1].numpy())]\n",
    "\n",
    "# Get edge weights from adjacency matrix for edge colors/transparency\n",
    "edge_weights = nx.get_edge_attributes(g, 'weight')\n",
    "if not edge_weights:  # If weights not in graph attributes, get from adjacency matrix\n",
    "    edge_weights = {(i,j): adj[i,j] for i,j in g.edges()}\n",
    "\n",
    "# Normalize weights to use as alpha values\n",
    "max_weight = max(edge_weights.values())\n",
    "edge_alphas = [edge_weights[edge]/max_weight for edge in g.edges()]\n",
    "# Rescale between min max of edge_alphas\n",
    "# minmax_edge_alphas = (max(edge_alphas) - edge_alphas)/(max(edge_alphas) - min(edge_alphas))\n",
    "\n",
    "# Get node colors based on subclass\n",
    "# Get unique subclasses\n",
    "unique_subclasses = data.obs[\"subclass\"].unique()\n",
    "\n",
    "# Get Tableau color palette with enough colors for all subclasses\n",
    "tableau_colors = sns.color_palette(\"tab20\", n_colors=len(unique_subclasses))\n",
    "\n",
    "# Create dictionary mapping subclasses to RGB colors\n",
    "color_map = dict(zip(unique_subclasses, tableau_colors))\n",
    "\n",
    "# Get node colors using the color map\n",
    "node_colors = [color_map[data.obs[\"subclass\"].iloc[i]] for i in range(len(g.nodes()))]\n",
    "\n",
    "# Draw the network\n",
    "# Draw edges\n",
    "\n",
    "# Draw nodes\n",
    "nx.draw_networkx_nodes(g, pos,\n",
    "                      node_size=20,\n",
    "                      node_color=node_colors,  # Color nodes by subclass\n",
    "                      alpha=0.5)\n",
    "nx.draw_networkx_edges(g, pos,\n",
    "                      edge_color='gray',\n",
    "                      width=1,\n",
    "                      alpha=2*edge_alphas)\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n"
   ],
   "id": "7c1cf2ff7ff6a118",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from lightning import LightningDataModule\n",
    "# The dataset is expected to be something like x_lr\n",
    "# we will consider for each interaction a different image of n_locations x n_locations\n",
    "class CustomInterScoreDataset(LightningDataModule):\n",
    "    def __init__(self, annotations_file):\n",
    "        self.interaction_labels = pd.read_csv(annotations_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.interaction_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        pass\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "f7c030f6de46fd8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Investigating LRTFTG interactions",
   "id": "68caff2be9b67381"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import nichecompass as nc\n",
    "lrt_interactions = nc.utils.extract_gp_dict_from_nichenet_lrt_interactions(\n",
    "    species=\"mouse\",\n",
    "    gene_orthologs_mapping_file_path=Path(os.getcwd()).parents[0] / \"data\" / \"raw\" / \"human_mouse_gene_orthologs.csv\",\n",
    "    plot_gp_gene_count_distributions=False,\n",
    ")\n",
    "lrt_df = pd.DataFrame.from_dict(lrt_interactions, orient='index')"
   ],
   "id": "c169ba694dd1e47b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import nichenet from gr.csv and lr_sig.csv\n",
    "gr_df = pd.read_csv(Path(os.getcwd()).parents[0] / \"data\" / \"raw\" / \"gr.csv\")\n",
    "gr_df.index = gr_df[\"from\"] + \"&\" + gr_df[\"to\"]"
   ],
   "id": "dd72a5d5a229a3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "gr_df",
   "id": "bdcc08c93683f4ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.boxplot(gr_df[\"weight\"])\n",
    "print(gr_df[\"weight\"].min(), gr_df[\"weight\"].max())"
   ],
   "id": "21377ff222a924e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lr_sig_df = pd.read_csv(Path(os.getcwd()).parents[0] / \"data\" / \"raw\" / \"lr_sig.csv\")\n",
    "lr_sig_df.index = lr_sig_df[\"from\"] + \"&\" + lr_sig_df[\"to\"]"
   ],
   "id": "428343c404e5897c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "lr_sig_df",
   "id": "bf470ec0dfd4695f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.boxplot(lr_sig_df[\"weight\"])\n",
    "print(lr_sig_df[\"weight\"].min(), lr_sig_df[\"weight\"].max())"
   ],
   "id": "8899791be57e2696",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(gr_df.info())\n",
    "print(lr_sig_df.info())\n",
    "print(f\"Number of unique senders in grn: {len(gr_df[\"from\"].unique())}/{len(gr_df[\"from\"])} which is the {len(gr_df[\"from\"].unique())/len(gr_df[\"from\"])*100:.2f}%\")\n",
    "print(f\"Number of unique receivers in grn: {len(gr_df[\"to\"].unique())}/{len(gr_df[\"to\"])} which is the {len(gr_df[\"to\"].unique())/len(gr_df[\"to\"])*100:.2f}%\")\n",
    "print(f\"Number of unique ligands in lr_sig: {len(lr_sig_df[\"from\"].unique())}/{len(lr_sig_df[\"from\"])} which is the {len(lr_sig_df[\"from\"].unique())/len(lr_sig_df[\"from\"])*100:.2f}%\")\n",
    "print(f\"Number of unique receptors in lr_sig: {len(lr_sig_df[\"to\"].unique())}/{len(lr_sig_df[\"to\"])} which is the {len(lr_sig_df[\"to\"].unique())/len(lr_sig_df[\"to\"])*100:.2f}%\")\n",
    "print(f\"Number of intersection between target genes in grn and ligands in lr: {len(set(gr_df[\"to\"].unique()).intersection(set(lr_sig_df[\"from\"].unique())))}/\" \\\n",
    "      + f\"{len(set(gr_df[\"to\"].unique()))} which is the {len(set(gr_df[\"to\"].unique()).intersection(set(lr_sig_df[\"from\"].unique())))/len(set(gr_df[\"to\"].unique()))*100:.2f}%\")\n",
    "print(f\"Number of intersection between senders in grn and ligands in lr: {len(set(gr_df[\"from\"].unique()).intersection(set(lr_sig_df[\"from\"].unique())))}/\" \\\n",
    "      + f\"{len(set(gr_df[\"from\"].unique()))} which is the {len(set(gr_df[\"from\"].unique()).intersection(set(lr_sig_df[\"from\"].unique())))/len(set(gr_df[\"from\"].unique()))*100:.2f}%\")\n",
    "print(f\"Number of intersection between target genes in grn and receptors in lr: {len(set(gr_df[\"to\"].unique()).intersection(set(lr_sig_df[\"to\"].unique())))}/\" \\\n",
    "      + f\"{len(set(gr_df[\"to\"].unique()))} which is the {len(set(gr_df[\"to\"].unique()).intersection(set(lr_sig_df[\"to\"].unique())))/len(set(gr_df[\"to\"].unique()))*100:.2f}%\")\n",
    "\n",
    "# How many senders are not receivers\n",
    "print(f\"Number of senders that are not target genes in grn: {len(set(gr_df[\"from\"].unique()).difference(set(gr_df[\"to\"].unique())))}\")\n",
    "print(f\"Number of target genes that are not senders in grn: {len(set(gr_df[\"to\"].unique()).difference(set(gr_df[\"from\"].unique())))}\")\n",
    "print(f\"Number of ligands that are not receptors in lr: {len(set(lr_sig_df[\"from\"].unique()).difference(set(lr_sig_df[\"to\"].unique())))}\")\n",
    "print(f\"Number of receptors that are not ligands in lr: {len(set(lr_sig_df[\"to\"].unique()).difference(set(lr_sig_df[\"from\"].unique())))}\")\n",
    "\n",
    "# How many intersections do i have with the lr from consensus mouse omnipath\n",
    "print(f\"Number of ligands that are reported in an interaction in omnipath and present in dataset: {\n",
    "len(set(lr_sig_df[\"from\"].str.lower().unique()).intersection(lr_df[\"ligand\"].unique()))\n",
    "}/{\n",
    "len(lr_sig_df[\"from\"].unique())} which is the {len(set(lr_sig_df[\"from\"].str.lower().unique()).intersection(lr_df[\"ligand\"].unique()))/len(lr_sig_df[\"from\"].unique())*100:.2f}%\")\n",
    "print(f\"Number of receptors that are reported in an interaction in omnipath and present in dataset: {len(set(lr_sig_df[\"to\"].str.lower().unique()).intersection(lr_df[\"receptor\"].unique()))}/\" \\\n",
    "      + f\"{len(lr_df[\"receptor\"].unique())} which is the {len(set(lr_df[\"receptor\"].unique()).intersection(lr_sig_df[\"to\"].str.lower().unique()))/len(lr_df[\"receptor\"].unique())*100:.2f}%\")"
   ],
   "id": "97d61cb08ca65c17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Compute element of venn diagram\n",
    "senders_grn = set(gr_df[\"from\"])\n",
    "receivers_grn = set(gr_df[\"to\"])\n",
    "senders_lr = set(lr_sig_df[\"from\"])\n",
    "receivers_lr = set(lr_sig_df[\"to\"])\n",
    "i = senders_grn.intersection(receivers_lr).intersection(senders_lr).intersection(receivers_lr)\n",
    "h = senders_lr.intersection(receivers_lr).intersection(receivers_grn) - i\n",
    "f = senders_grn.intersection(senders_lr).intersection(receivers_grn) - i\n",
    "e = senders_grn.intersection(receivers_grn).intersection(receivers_lr) - i\n",
    "g = senders_grn.intersection(senders_lr).intersection(receivers_lr) - i\n",
    "a = senders_grn.intersection(receivers_grn) - f - e - i\n",
    "b = senders_grn.intersection(senders_lr) - f - g - i\n",
    "c = senders_lr.intersection(receivers_lr) - g - i - h\n",
    "d = receivers_lr.intersection(receivers_grn) - e - i - h\n",
    "num_isolated_senders_grn = len(senders_grn - a - b - f - g - e - i)\n",
    "num_isolated_senders_lr = len(senders_lr - b - c - f - g - h - i)\n",
    "num_isolated_receivers_grn = len(receivers_grn - a - d - f - e - i - h)\n",
    "num_isolated_receivers_lr = len(receivers_lr - c - d - g - h - i - e)\n",
    "\n",
    "print(len(senders_grn), len(senders_lr), len(receivers_grn), len(receivers_lr))\n",
    "print(num_isolated_senders_grn, num_isolated_senders_lr, num_isolated_receivers_grn, num_isolated_receivers_lr)\n",
    "print([len(a), len(b), len(c), len(d), len(e), len(f), len(g), len(h), len(i)])"
   ],
   "id": "8ebe748b8a372e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plt.hist(gr_df[\"to\"].value_counts().values, bins=20)",
   "id": "5241e9032bdd9712",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "g = nx.DiGraph([(sender, receiver) for sender, receiver in zip(gr_df.index, gr_df[\"to\"])])\n",
    "print(g)"
   ],
   "id": "db7d0503cd6cba7f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "g = nx.DiGraph()\n",
    "for i, row in lr_df.iterrows():\n",
    "    g.add_edge(row[\"ligand\"], row[\"receptor\"])\n",
    "print(g)\n",
    "fig,axs = plt.subplots(nrows=1, ncols=1, figsize=(40,40))\n",
    "node_sizes = [10*g.degree(n) for n in g.nodes()]\n",
    "nx.draw(g, with_labels=True, font_size=8, pos=nx.spring_layout(g), node_size = node_sizes, ax=axs)"
   ],
   "id": "a1e2a43aae560c03",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Let's work with omnipath",
   "id": "44c95d80efadb682"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pypath import omnipath\n",
    "from pypath import core\n",
    "op = omnipath.db.datasets\n",
    "print(op)"
   ],
   "id": "7f8220e27bcbf8ff",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "omni_net = core.network.Network(resources=\"omnipath\", make_df=True)",
   "id": "8493884dde7a2168",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "omni_net.make_df()",
   "id": "73a4a241500b0d56",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(omni_net.df.info())\n",
    "omni_net.df.to_csv(Path(os.getcwd()).parents[0] / \"data\" / \"raw\" / \"omni_net_human.csv\")"
   ],
   "id": "b200c771ec90da35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "omni_net = pd.read_csv(Path(os.getcwd()).parents[0] / \"data\" / \"raw\" / \"omni_net_human.csv\")",
   "id": "9511a0c2d7bf0973",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(omni_net.info())",
   "id": "dc322778ea0fe05e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import pypath",
   "id": "d22e3c0961db5ac0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "biomart_homology = pypath.inputs.biomart.biomart_homology(source_organism=\"human\", target_organism=\"mouse\")",
   "id": "cf616bc1cb6cc7a1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "biomart_homologene_class = pypath.utils.orthology.HomologeneOrthology(\n",
    "    target=\"mouse\", source=\"human\",\n",
    ")"
   ],
   "id": "6bc5b7d9f900f7f7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "omni_net",
   "id": "9600c79e0e96a67d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "translated_omni_net = biomart_homologene_class.translate_df(omni_net, cols=[\"id_a\",\"id_b\"])",
   "id": "ce5904db0cbf9ba4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "translated_omni_net",
   "id": "c4ea6008b4d5c2fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "id_a_set = set(translated_omni_net[\"id_a\"].unique())\n",
    "id_b_set = set(translated_omni_net[\"id_b\"].unique())\n",
    "all_known_genes = id_a_set.union(id_b_set)\n",
    "\n"
   ],
   "id": "19f96589c8874814",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "with open(Path(os.getcwd()).parents[0] / \"data\" / \"raw\" / \"omni_network_swissprot_mouse_ids.txt\", \"w\") as f:\n",
    "    f.write(str(all_known_genes))\n",
    "    f.close()"
   ],
   "id": "e5e7fc22cee224c5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "map_uniprot_to_gene_symbol = pd.read_csv(Path(os.getcwd()).parents[0] / \"data\" / \"raw\" / \"idmap.csv\")\n",
    "print(map_uniprot_to_gene_symbol.shape)\n",
    "map_uniprot_to_gene_symbol.index = map_uniprot_to_gene_symbol[\"query\"]"
   ],
   "id": "fd694026b5e0711f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f\"How many genes have we mapped: {len(set(map_uniprot_to_gene_symbol[\"query\"]).intersection(all_known_genes))/len(all_known_genes)*100:.2f}%\")",
   "id": "64f7981ccec911ee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "translated_omni_net[\"id_a\"] = translated_omni_net[\"id_a\"].map(map_uniprot_to_gene_symbol[\"symbol\"].to_dict())\n",
    "translated_omni_net[\"id_b\"] = translated_omni_net[\"id_b\"].map(map_uniprot_to_gene_symbol[\"symbol\"].to_dict())"
   ],
   "id": "df6ba4737c89af25",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "map_from_human_to_mouse_ortologs = pd.read_csv(Path(os.getcwd()).parents[0] / \"data\" / \"raw\" / \"human_mouse_gene_orthologs.csv\")\n",
    "print(map_from_human_to_mouse_ortologs)\n",
    "print(omni_net.df[\"id_a\"].unique())\n",
    "print(len(set(map_from_human_to_mouse_ortologs[\"Gene name\"]).intersection(omni_net.df[\"id_b\"])))"
   ],
   "id": "555b57239b742b7e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Omnipath can translate between a large variety of gene, protein, miRNA and small molecule ID.\n",
    "\n",
    "Omnipath can translate homologous genes, finding orthologs between two organims.\n",
    "\n",
    "Omnipath contains the following:\n",
    "- omnipath (activity flow, enzyme-substrate, lr interactions)\n",
    "- curated (PPI network)\n",
    "- complex\n",
    "- annotations (HUGE database)\n",
    "- intercell (requires annotations)\n",
    "- tf_target\n",
    "- dorothea (collectri is newer)\n",
    "- small_molecule\n",
    "- tf_mirna\n",
    "- mirna_mrna\n",
    "- lncrna_mrna\n",
    "- enz_sub\n"
   ],
   "id": "7e5c643f305f5eff"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "translated_omni_net.effect.value_counts()",
   "id": "d3d3b7ac78154574",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(f\"How many sources of omni_net are present in x hat s: \" + \\\n",
    "      f\"{len(set(translated_omni_net['id_a'].str.lower()).intersection(x_hat_s.var_names))/len(x_hat_s.var_names)*100:.2f}% of x hat s\")\n",
    "print(f\"How many receivers of omni_net are present in database: \" + \\\n",
    "      f\"{len(set(translated_omni_net['id_b'].str.lower()).intersection(x_hat_s.var_names))/len(x_hat_s.var_names)*100:.2f}% of x hat s\")\n",
    "print(f\"How many source of omni_net are present in x f: \" + \\\n",
    "      f\"{len(set(translated_omni_net[\"id_a\"].str.lower()).intersection(data.var_names))/len(data.var_names)*100:.2f}% of x f\")\n",
    "print(f\"How many receivers of omni_net are present in x f: \" + \\\n",
    "      f\"{len(set(translated_omni_net[\"id_b\"].str.lower()).intersection(data.var_names))/len(data.var_names)*100:.2f}% of x f\")"
   ],
   "id": "5c35ddd2b62854d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "d = set(translated_omni_net[\"id_a\"].str.lower()).intersection(set(translated_omni_net[\"id_b\"].str.lower())).intersection(data.var_names)\n",
    "a = set(translated_omni_net[\"id_a\"].str.lower()).intersection(set(translated_omni_net[\"id_b\"]))-d\n",
    "b = set(translated_omni_net[\"id_a\"].str.lower()).intersection(data.var_names) - d\n",
    "c = set(translated_omni_net[\"id_b\"].str.lower()).intersection(data.var_names) - d\n",
    "print(len(d), len(a), len(b), len(c))\n",
    "print(len(data.var_names) - len(b) - len(d) - len(c))\n",
    "print(len(set(translated_omni_net[\"id_a\"].str.lower())) - len(a) - len(d) - len(b))\n",
    "print(len(set(translated_omni_net[\"id_b\"].str.lower())) - len(a) - len(d) - len(c))"
   ],
   "id": "98f708719cd8b484",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "d = set(translated_omni_net[\"id_a\"].str.lower()).intersection(set(translated_omni_net[\"id_b\"].str.lower())).intersection(x_hat_s.var_names)\n",
    "a = set(translated_omni_net[\"id_a\"].str.lower()).intersection(set(translated_omni_net[\"id_b\"]))-d\n",
    "b = set(translated_omni_net[\"id_a\"].str.lower()).intersection(x_hat_s.var_names) - d\n",
    "c = set(translated_omni_net[\"id_b\"].str.lower()).intersection(x_hat_s.var_names) - d\n",
    "print(len(d), len(a), len(b), len(c))\n",
    "print(len(x_hat_s.var_names) - len(b) - len(d) - len(c))\n",
    "print(len(set(translated_omni_net[\"id_a\"].str.lower())) - len(a) - len(d) - len(b))\n",
    "print(len(set(translated_omni_net[\"id_b\"].str.lower())) - len(a) - len(d) - len(c))"
   ],
   "id": "8b293bee777185dc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "a = set(translated_omni_net[\"id_a\"].str.lower()).intersection(\n",
    "    translated_omni_net[\"id_b\"].str.lower()\n",
    ").intersection(\n",
    "    gr_df[\"from\"].str.lower()\n",
    ").intersection(\n",
    "    gr_df[\"to\"].str.lower()\n",
    ")\n",
    "g = set(translated_omni_net[\"id_a\"].str.lower()).intersection(\n",
    "    translated_omni_net[\"id_b\"].str.lower()\n",
    ").intersection(\n",
    "    gr_df[\"from\"].str.lower()\n",
    ") - a\n",
    "h = set(translated_omni_net[\"id_a\"].str.lower()).intersection(\n",
    "    gr_df[\"from\"].str.lower()\n",
    ").intersection(\n",
    "    gr_df[\"to\"].str.lower()\n",
    ") -a\n",
    "i = set(translated_omni_net[\"id_b\"].str.lower()).intersection(\n",
    "    gr_df[\"from\"].str.lower()\n",
    ").intersection(\n",
    "    gr_df[\"to\"].str.lower()\n",
    ") -a\n",
    "f = set(translated_omni_net[\"id_a\"].str.lower()).intersection(\n",
    "    translated_omni_net[\"id_b\"].str.lower()\n",
    ").intersection(\n",
    "    gr_df[\"to\"].str.lower()\n",
    ") -a\n",
    "b = set(translated_omni_net[\"id_a\"].str.lower()).intersection(\n",
    "    translated_omni_net[\"id_b\"].str.lower()\n",
    ") - g - f - a\n",
    "c = set(translated_omni_net[\"id_a\"].str.lower()).intersection(\n",
    "    gr_df[\"from\"].str.lower()\n",
    ") - g - h - a\n",
    "d = set(gr_df[\"from\"].str.lower()).intersection(\n",
    "    gr_df[\"to\"].str.lower()\n",
    ") - h - i - a\n",
    "e = set(translated_omni_net[\"id_b\"].str.lower()).intersection(\n",
    "    gr_df[\"to\"].str.lower()\n",
    ") - f - i - a\n",
    "print(len(a), len(b), len(c), len(d), len(e), len(f), len(g), len(h), len(i))"
   ],
   "id": "2a31b05b190503a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_isolated_id_a = len(set(translated_omni_net[\"id_a\"].str.lower()) -c-b-g-h-a-f)\n",
    "num_isolated_id_b = len(set(translated_omni_net[\"id_b\"].str.lower()) -b-e-g-f-a-i)\n",
    "num_isolated_regulators = len(set(gr_df[\"from\"].str.lower())-c-g-a-h-i-d)\n",
    "num_isolated_regulated = len(set(gr_df[\"to\"].str.lower())-e-f-a-h-i-d)\n",
    "print(num_isolated_id_a, num_isolated_id_b, num_isolated_regulators, num_isolated_regulated)\n",
    "print(len(set(translated_omni_net[\"id_a\"].str.lower())),\n",
    "      len(set(translated_omni_net[\"id_b\"].str.lower())),\n",
    "      len(set(gr_df[\"from\"].str.lower())),\n",
    "      len(set(gr_df[\"to\"].str.lower())))"
   ],
   "id": "6437e4a221fac3f2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "lr_df",
   "id": "3ba58631b71ade28",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
